# -*- coding: utf-8 -*-
"""001_face_crop_mtcnn

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t7MEto184ul9OGrk_ZMYo1IwNGd97Tn3

# 딥페이크 인식 1등팀이 사용한 mtcnn_face_crop 전체코드

# 적당히 필요할만한것들을 골라서 적용
"""

import tensorflow as tf
import cv2
import numpy as np

from glob import glob
import os
import sys
import argparse
import shutil

from glob import glob


fake_image = glob('D:/test_image_new/fake/*.jpg')
fake_image.sort()
fake_image[0].split('/')[-1]

real_image = glob('D:/test_image_new/real/*.jpg')
real_image.sort()

test_image = glob('D:/test/leaderboard/*.jpg')
test_image.sort()

from mtcnn import MTCNN

# 이건 mtcnn의 결과 모양 확인용
path = test_image[4083]
img = cv2.imread(path)
detector = MTCNN()
results = detector.detect_faces(img)
print(results)

# 보니깐 2개 이상의 얼굴을 detect하는경우는 진짜 얼굴을 대부분 캐치하는데 그 이후에 엄청 작은 영역을 얼굴로 인식해서 results에 들어가서
# 가장 큰 사이즈의 박스를 고름. 대부분 첫번째(0번째 index)인거 같은데 혹시 몰라서 1등팀의 코드에서 참고
def get_max_size_box(results):
    max_idx = 0
    max_size = 0
    i = 0

    for result in results:
      box = result['box']
      w = box[3]
      h = box[2]
      box_size = w * h
      if max_size < box_size:
          max_size = box_size
          max_idx = i
      i += 1
    return max_idx

from mtcnn import MTCNN
import cv2
err_path = []

# fake image에 대한 crop
for i in range(len(fake_image)):
  path = fake_image[i]  # face extract 할 path를 지정 (fake/real/test)
  img = cv2.imread(path)
  detector = MTCNN()
  results = detector.detect_faces(img)

  # mtcnn은 뒤집어진 얼굴은 인식을 못함. 실제 우리 데이터에도 뒤집어놓은 사진이 존재함.
  if len(results)<1:
    img = cv2.rotate(img, cv2.ROTATE_180)
    results = detector.detect_faces(img)
  
  # 얼굴 못찾은경우
  if len(results)<1:
    print(path)
    continue
  
  bounding_box = []
  if len(results)==1:
    bounding_box = results[0]['box']   # mtcnn의 detect_faces가 detect한 얼굴의 네 좌표
  else:
    idx = get_max_size_box(results)
    bounding_box = results[idx]['box']
  
  margin_x = bounding_box[2] * 0.1  # 20% as margin
  margin_y = bounding_box[3] * 0.135  # 27% as margin

  x1 = int(bounding_box[0] - margin_x)
  if x1 < 0:
    x1 = 0
        
  x2 = int(bounding_box[0] + bounding_box[2] + margin_x)
  if x2 > img.shape[1]:
    x2 = img.shape[1]
          
  y1 = int(bounding_box[1] - margin_y)
  if y1 < 0:
    y1 = 0
          
  y2 = int(bounding_box[1] + bounding_box[3] + margin_y)
  if y2 > img.shape[0]:
    y2 = img.shape[0]

  face_image = img[y1:y2,x1:x2].copy()

  # 이건 EfficientNetB4의 input size가 (380, 380) 이 가장 효과적이기 때문. 
  # resize를 train할때 해도 되는데 training에서의 computation 최대한 줄이려고 미리 사용
  face_image = cv2.resize(face_image, (380, 380)) 

  name = path.split('/')[-1]
  new_filename= ('D:/test_image_new/face_crop/' + name).replace("\\", "/", 1)
  print("Current: " + new_filename + " ETA: " + str(len(fake_image)-i))
  cv2.imwrite(new_filename, face_image)


# real image에 대한 crop
for i in range(len(real_image)):
  path = fake_image[i]  # face extract 할 path를 지정 (fake/real/test)
  img = cv2.imread(path)
  detector = MTCNN()
  results = detector.detect_faces(img)

  # mtcnn은 뒤집어진 얼굴은 인식을 못함. 실제 우리 데이터에도 뒤집어놓은 사진이 존재함.
  if len(results)<1:
    img = cv2.rotate(img, cv2.ROTATE_180)
    results = detector.detect_faces(img)
  
  # 얼굴 못찾은경우
  if len(results)<1:
    print(path)
    continue
  
  bounding_box = []
  if len(results)==1:
    bounding_box = results[0]['box']   # mtcnn의 detect_faces가 detect한 얼굴의 네 좌표
  else:
    idx = get_max_size_box(results)
    bounding_box = results[idx]['box']
  
  margin_x = bounding_box[2] * 0.1  # 20% as margin
  margin_y = bounding_box[3] * 0.135  # 27% as margin

  x1 = int(bounding_box[0] - margin_x)
  if x1 < 0:
    x1 = 0
        
  x2 = int(bounding_box[0] + bounding_box[2] + margin_x)
  if x2 > img.shape[1]:
    x2 = img.shape[1]
          
  y1 = int(bounding_box[1] - margin_y)
  if y1 < 0:
    y1 = 0
          
  y2 = int(bounding_box[1] + bounding_box[3] + margin_y)
  if y2 > img.shape[0]:
    y2 = img.shape[0]

  face_image = img[y1:y2,x1:x2].copy()

  # 이건 EfficientNetB4의 input size가 (380, 380) 이 가장 효과적이기 때문. 
  # resize를 train할때 해도 되는데 training에서의 computation 최대한 줄이려고 미리 사용
  face_image = cv2.resize(face_image, (380, 380)) 

  name = path.split('/')[-1]
  new_filename= ('D:/test_image_new/face_crop/' + name).replace("\\", "/", 1)
  print(new_filename)
  cv2.imwrite(new_filename, face_image)
